{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import feature_engine.transformation as vt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "# the scaler - for min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.read_csv('data/fifa_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature = ['gk_diving','gk_handling','gk_kicking','gk_reflexes','defending_marking','attacking_crossing','attacking_finishing',\n",
    "'attacking_short_passing','attacking_volleys','defending_median','defending_sliding_tackle',\n",
    "'defending_standing_tackle','dribbling_median','goalkeeping_diving','goalkeeping_handling','goalkeeping_kicking','goalkeeping_positioning',\n",
    "'goalkeeping_reflexes','mentality_aggression','mentality_composure','mentality_interceptions','mentality_penalties','mentality_positioning',\n",
    "'movement_acceleration','movement_agility','movement_balance','movement_sprint_speed','passing_median','physic_median',\n",
    "'power_long_shots','power_shot_power','power_stamina','shooting_median','skill_curve','skill_fk_accuracy',\n",
    "'skill_long_passing','wage_eur','weight_kg']\n",
    "\n",
    "for feature in range(len(drop_feature)):\n",
    "    dfnew = dfnew.drop([drop_feature[feature]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'height_cm', 'overall', 'potential', 'value_eur',\n",
       "       'preferred_foot', 'weak_foot', 'skill_moves', 'work_rate',\n",
       "       'team_position', 'attacking_heading_accuracy', 'skill_dribbling',\n",
       "       'skill_ball_control', 'movement_reactions', 'power_jumping',\n",
       "       'power_strength', 'mentality_vision', 'pace_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew.to_csv(\"fifa_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 16 numerical features : ['age', 'height_cm', 'overall', 'potential', 'value_eur', 'preferred_foot', 'weak_foot', 'skill_moves', 'attacking_heading_accuracy', 'skill_dribbling', 'skill_ball_control', 'movement_reactions', 'power_jumping', 'power_strength', 'mentality_vision', 'pace_median']\n",
      "We have 2 categorical features : ['work_rate', 'team_position']\n"
     ]
    }
   ],
   "source": [
    "# numerical and categorical features\n",
    "numerical_features = [feature for feature in dfnew.columns if dfnew[feature].dtype != 'O']\n",
    "categorical_feature = [feature for feature in dfnew.columns if dfnew[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numerical_features), numerical_features))\n",
    "print('We have {} categorical features : {}'.format(len(categorical_feature), categorical_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets move towards splitting the data.\n",
    "\n",
    "# get the locations\n",
    "y = dfnew['overall']\n",
    "X = dfnew.drop(columns=['overall'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column transformer with 3 types of transformer\n",
    "\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\" : LinearRegression(),\n",
    "    \"Lasso\" : Lasso(),\n",
    "    \"Ridge\" : Ridge(),\n",
    "    \"Random Forest Regressor\" : RandomForestRegressor(),\n",
    "    \"XGBRegressor\" : XGBRegressor(),\n",
    "    \"CatBoosting Regressor\" : CatBoostRegressor(verbose = False),\n",
    "    \"AdaBoost Regressor\" : AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate train and test set\n",
    "    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print(\"model performance for training dataset\")\n",
    "    print(\"- Root mean Sqared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- mean absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- r2 score: {:.4f}\".format(model_train_r2))\n",
    "    r2_list.append(model_train_r2)\n",
    "\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    print(\"Model performace on test dataset\")\n",
    "    print(\"- Root mean Sqared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- mean absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- r2 score: {:.4f}\".format(model_test_r2))  \n",
    "    r2_list.append(model_test_r2)\n",
    "\n",
    "\n",
    "    print(\"=\"*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name','R2_Score']).sort_values(by=['R2_Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression(fit_intercept=True)\n",
    "lin_model = lin_model.fit(X_train, y_train)\n",
    "y_pred = lin_model.predict(X_test)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\"Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred);\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred, ci=None, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'Actual Value': y_test, 'Predicted Value': y_pred, 'Difference': y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "067776ecfe78b5bd2a3a19e4f48cb0a62d140d7985497b6a99b954c5e0b4b3f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
